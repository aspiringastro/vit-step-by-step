{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNy+kcL1su4Zdn/s+11MvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aspiringastro/vit-step-by-step/blob/main/vit_version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7winnVlZ7Rfw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR10DataSet():\n",
        "    def __init__(self, data_dir=\"data/cifar10\", train_val_split=0.8):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset = CIFAR10(root=self.data_dir, download=True)\n",
        "        self.mean = (0.485, 0.456, 0.406)\n",
        "        self.std = (0.229, 0.224, 0.225)\n",
        "        self.train_val_split = train_val_split\n",
        "\n",
        "    def  train_dataloader(self, batch_size=32, resize=32, p=0.5, mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225), num_workers=4):\n",
        "        tf = T.Compose([\n",
        "                T.RandomResizedCrop(size=resize),\n",
        "                T.RandomHorizontalFlip(p=p),\n",
        "                T.RandomVerticalFlip(p=p),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        ds = CIFAR10(root=self.data_dir, train=True, transform=tf)\n",
        "        num_train = len(ds)\n",
        "        indices = list(range(num_train))\n",
        "        split = int(np.floor(self.train_val_split * num_train))\n",
        "        train_sampler = SubsetRandomSampler(indices[split:])\n",
        "        dl = DataLoader(\n",
        "            ds,\n",
        "            batch_size=batch_size, \n",
        "            num_workers=num_workers, \n",
        "            sampler=train_sampler, \n",
        "            drop_last=True\n",
        "            )\n",
        "        return dl\n",
        "    \n",
        "    def  val_dataloader(self, batch_size=32, resize=32, p=0.5, mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225), num_workers=4):\n",
        "        tf = T.Compose([\n",
        "                T.RandomResizedCrop(size=resize),\n",
        "                T.RandomHorizontalFlip(p=p),\n",
        "                T.RandomVerticalFlip(p=p),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        ds = CIFAR10(root=self.data_dir, train=True, transform=tf)\n",
        "        num_train = len(ds)\n",
        "        indices = list(range(num_train))\n",
        "        split = int(np.floor(self.train_val_split * num_train))\n",
        "        val_sampler = SubsetRandomSampler(indices[:split])\n",
        "        dl = DataLoader(\n",
        "            ds,\n",
        "            batch_size=batch_size, \n",
        "            num_workers=num_workers, \n",
        "            sampler=val_sampler, \n",
        "            drop_last=True\n",
        "            )\n",
        "        return dl\n",
        "\n",
        "    \n",
        "    def test_dataloader(self, batch_size=32, mean=(0.485, 0.456, 0.406) ,std=(0.229, 0.224, 0.225), num_workers=2):\n",
        "        tf = T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        ds = CIFAR10(root=self.data_dir, train=False, transform=tf)\n",
        "        dl = DataLoader(ds,batch_size=batch_size, num_workers=num_workers, drop_last=True)\n",
        "        return dl\n",
        "    \n",
        "    def get_next(self, dl):\n",
        "        return next(iter(dl))\n",
        "    \n",
        "    def get_classes(self):\n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        return classes\n",
        "\n"
      ],
      "metadata": {
        "id": "jyE-1BRS7XHa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.utils\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
        "\n",
        "def make_image(img, mean=(0., 0., 0.), std=(1., 1., 1.)):\n",
        "    #denormalize\n",
        "    for i in range(3):\n",
        "        img[i] = img[i] * std[i] + mean[i]\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "def show_image(imgs, mean=(0., 0., 0.), std=(1., 1., 1.)):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        for j in range(3):\n",
        "            img[j] = img[j] * std[j] + mean[j]\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "def show_images(imgs, mean=(0., 0., 0.), std=(1., 1., 1.)):\n",
        "    grid_imgs = make_grid(imgs)\n",
        "    grid_imgs = make_image(grid_imgs, mean, std)\n",
        "    plt.imshow(grid_imgs)\n",
        "    plt.axis('off')\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "rbich_FF7aRJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "eval_iters = 200\n",
        "dropout = 0.2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "DkVgyrqq7cZq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CIFAR10DataSet()\n",
        "downloader = dataset.train_dataloader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KvJ8QfxADTl",
        "outputId": "9b33c22b-0d92-4956-961a-90a1dc4650bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(dataset, split, batch_size=32):\n",
        "    if split == 'train':\n",
        "        downloader = dataset.train_dataloader(batch_size=batch_size)\n",
        "    elif split == 'val':\n",
        "        downloader = dataset.val_dataloader(batch_size=batch_size)\n",
        "    elif split == 'test':\n",
        "        downloader = dataset.test_dataloader(batch_size=batch_size)\n",
        "    else:\n",
        "        raise AttributeError(f'Invalid Split parameter ({split}) provided.')\n",
        "    x, y_label = dataset.get_next(downloader)\n",
        "    y = F.one_hot(y_label, num_classes=len(dataset.get_classes()))\n",
        "    x, y = x.to(device), y.float().to(device)\n",
        "    return x,y\n",
        "\n",
        "dataset = CIFAR10DataSet()\n",
        "\n",
        "x, y = get_batch(dataset, \"train\")\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "x_val, y_val = get_batch(dataset, \"val\")\n",
        "print(x_val.shape, y_val.shape)\n",
        "\n",
        "x_test, y_test= get_batch(dataset, \"test\")\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YkG_g0p7jtg",
        "outputId": "91075f66-150d-4892-89a5-d0b593c7a811"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n",
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n",
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Patch embed layer that takes a 2D image to create embed patches of size P\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size, patch_size, in_chans=3, embed_dim=96):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size) ** 2\n",
        "        self.patch_embd = nn.Conv2d(\n",
        "            in_chans,\n",
        "            embed_dim,\n",
        "            kernel_size=patch_size, \n",
        "            stride=patch_size,\n",
        "            device=device,\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # print(f\"PatchEmbedding: x.shape: {x.shape}\")\n",
        "        x = self.patch_embd(x)\n",
        "        # print(f\"PatchEmbedding: patch_embd(x).shape: {x.shape}\")\n",
        "        x = x.flatten(2)\n",
        "        # print(f\"PatchEmbedding: flatten(patch_embed(x)).shape: {x.shape}\")\n",
        "        x = x.transpose(1,2)\n",
        "        # print(f\"PatchEmbedding: transpose(flatten(patch_embed(x)),(1,2)).shape: {x.shape}\")\n",
        "        return x"
      ],
      "metadata": {
        "id": "YBxiT17-7jO4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(dataset, split, batch_size=32):\n",
        "    if split == 'train':\n",
        "        downloader = dataset.train_dataloader(batch_size=batch_size)\n",
        "    elif split == 'val':\n",
        "        downloader = dataset.val_dataloader(batch_size=batch_size)\n",
        "    elif split == 'test':\n",
        "        downloader = dataset.test_dataloader(batch_size=batch_size)\n",
        "    else:\n",
        "        raise AttributeError(f'Invalid Split parameter ({split}) provided.')\n",
        "    x, y_label = dataset.get_next(downloader)\n",
        "    y = F.one_hot(y_label, num_classes=len(dataset.get_classes()))\n",
        "    return x,y.float()\n",
        "\n",
        "x, y = get_batch(dataset, \"train\")\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "x_val, y_val = get_batch(dataset, \"val\")\n",
        "print(x_val.shape, y_val.shape)\n",
        "\n",
        "x_test, y_test= get_batch(dataset, \"test\")\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66X8t0AM7l7B",
        "outputId": "eab749a0-a105-497a-e630-c6bb49e303e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n",
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n",
            "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of single attention \"\"\"\n",
        "    def __init__(self, head_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)  # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # sqrt of head size, (B,T,C) @ (B,T,C)^T => (B,T,C) @ (B,C,T) => (B,T,T)\n",
        "        wei = F.softmax(wei, dim=1) # (B,T,T)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x) #(B,T,C)\n",
        "        out = wei @ v # (B,T,T) @ (B,T,C) = (B,T,C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "rueKHPJf730V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size, n_embd) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat over channel dimension\n",
        "        out = self.proj(out) # projection is a linear transformation of the outcome of the previous multi-head layer\n",
        "        out = self.dropout(out) # dropout\n",
        "        return out"
      ],
      "metadata": {
        "id": "sVLF1dEP8ZwN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer of feedforward followed by non-linearity\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd), # projection layer in FFwd\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.nn(x)"
      ],
      "metadata": {
        "id": "PoxA5li98bqP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer Block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd : embedding dimension\n",
        "        # n_head : number of heads needed for multi-head self-attention\n",
        "        super().__init__()\n",
        "        assert n_embd % n_head == 0, f'n_embd {n_embd}, n_head: {n_head} must be a divisor'\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size, n_embd) # communication\n",
        "        self.ffwd = FeedForward(n_embd) # computation\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # No residual connections\n",
        "        # x = self.sa(x)\n",
        "        # x = self.ffwd(x)\n",
        "        # with residual connection\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2W7lbSIf8ddB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=96, n_classes=10, n_layers=4, n_heads=6):\n",
        "        super().__init__()\n",
        "        # Every patch sequence begins with a CLS token\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "\n",
        "        self.patch_embedding_table = PatchEmbedding(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        self.position_embedding_table = nn.Embedding(self.patch_embedding_table.n_patches, embedding_dim=embed_dim)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[ Block(embed_dim, n_heads) for _ in range(n_layers)],\n",
        "            nn.LayerNorm(embed_dim),\n",
        "        )\n",
        "        self.vm_head = nn.Linear(embed_dim, n_classes)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        n_samples, n_chans, n_patch, _ = idx.shape\n",
        "        # print(f\"VisionTransformerModel: n_samples={n_samples}, n_chans={n_chans}, n_patch={n_patch}\")\n",
        "        \n",
        "        patch_emb = self.patch_embedding_table(idx)\n",
        "        # print(f\"VisionTransformerModel: patch_emb shape={patch_emb.shape}\")\n",
        "        n_patches = self.patch_embedding_table.n_patches\n",
        "        pos_emb = self.position_embedding_table(torch.arange(n_patches, device=device))\n",
        "        # print(f\"VisionTransformerModel: pos_emb shape={pos_emb.shape}\")\n",
        "        x = patch_emb + pos_emb\n",
        "        # print(f\"VisionTransformerModel: x (after patch+pos) shape={x.shape}\")\n",
        "\n",
        "        # Prepend the cls_token\n",
        "        cls_token = self.cls_token.expand(n_samples, -1, -1)\n",
        "        # print(f\"VisionTransformerModel: cls_token shape={cls_token.shape}\")\n",
        "        x =  torch.cat((cls_token, x), dim=1)\n",
        "        # print(f\"VisionTransformerModel: x (after cat cls_token) shape={x.shape}\")\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        # print(f\"VisionTransformerModel: x.blocks shape={x.shape}\")\n",
        "\n",
        "        cls_token_final = x[:, 0]\n",
        "        # print(f\"VisionTransformerModel: cls_token_final shape={cls_token_final.shape}\")\n",
        "\n",
        "        logits = self.softmax(self.vm_head(cls_token_final))\n",
        "        \n",
        "        # print(f\"VisionTransformerModel: logits shape={logits.shape}\")\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # B, T, C = logits.shape\n",
        "            # print(f\"VisionTransformerModel: B T C shape={B} {T} {C}\")\n",
        "            # logits = logits.view(B*T, C)\n",
        "            # targets = targets.view(B*T)\n",
        "            # print(f\"VisionTransformerModel: Logits = {logits.shape}\\n{logits}\\n\")\n",
        "            # print(f\"VisionTransformerModel: Targets = {targets.shape}\\n{targets}\\n\")\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "    \n"
      ],
      "metadata": {
        "id": "nh53L8el8fe1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionTransformerModel()\n",
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "2RT1oZGu8kCq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(dataset, split)\n",
        "            logits, loss = m(X.to(device), Y.to(device))\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "OmnQhDPK8kec"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Hy2Zkt8mvv",
        "outputId": "847f14e6-5cc7-434a-b483-171fbeb5327d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.458314 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "max_iters = 1000\n",
        "eval_interval = 100\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "from tqdm import tqdm\n",
        "\n",
        "for it in tqdm(range(max_iters)):\n",
        "    \n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if it % eval_interval == 0 or it == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"\\tstep {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch(dataset, 'train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb.to(device), yb.to(device))\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3JtR59h8oV6",
        "outputId": "fef4f9ea-b5f4-4bf6-a48b-11cbbae202e3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 0: train loss 2.3043, val loss 2.3041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 100/1000 [07:50<14:01,  1.07it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-j6iy6ttl'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 100: train loss 2.2634, val loss 2.2718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 200/1000 [15:50<12:39,  1.05it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-4ox6n8ka'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 200: train loss 2.2508, val loss 2.2440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 300/1000 [24:00<11:30,  1.01it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-l4hrpj5y'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 300: train loss 2.2416, val loss 2.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 400/1000 [32:30<11:02,  1.10s/it]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-wzb24y4n'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 400: train loss 2.2456, val loss 2.2477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 500/1000 [41:12<08:36,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 500: train loss 2.2427, val loss 2.2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 600/1000 [50:04<06:58,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 600: train loss 2.2321, val loss 2.2337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 700/1000 [59:10<05:25,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 700: train loss 2.2287, val loss 2.2346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 800/1000 [1:08:27<03:44,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 800: train loss 2.2243, val loss 2.2292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 900/1000 [1:17:55<01:57,  1.17s/it]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 722, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.8/shutil.py\", line 720, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-vg31mase'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 900: train loss 2.2167, val loss 2.2235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 999/1000 [1:28:21<00:01,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tstep 999: train loss 2.2177, val loss 2.2278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [1:37:10<00:00,  5.83s/it] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(m, \"vit_base_attempt_1.pth\")"
      ],
      "metadata": {
        "id": "v-FM1nu5JPtX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 100\n",
        "xt, yt = get_batch(dataset, 'test', n_samples)\n",
        "xy, yt = xt.to(device), yt.to(device)\n",
        "k = 3\n",
        "labels = dataset.get_classes()\n",
        "logits = model(xt.to(device))\n",
        "print(logits[0].shape)\n",
        "softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "for j in range(n_samples):\n",
        "  target = labels[torch.argmax(yt[j])]\n",
        "  probs = softmax(logits[0][j])\n",
        "  top_probs, top_ics = probs.topk(k)\n",
        "\n",
        "\n",
        "  for i, (ix_, prob_) in enumerate(zip(top_ics, top_probs)):\n",
        "    ix = ix_.item()\n",
        "    prob = prob_.item()\n",
        "    cls = labels[ix].strip()\n",
        "    print(f\"{i}: {cls:<45} -- {prob*100.0:2.1f}% -- {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOB10tl8fBEo",
        "outputId": "0116b073-d016-432e-b095-ebec75d90c78"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 10])\n",
            "0: truck                                         -- 16.7% -- cat\n",
            "1: car                                           -- 11.5% -- cat\n",
            "2: ship                                          -- 9.4% -- cat\n",
            "0: plane                                         -- 18.2% -- ship\n",
            "1: ship                                          -- 10.8% -- ship\n",
            "2: dog                                           -- 9.0% -- ship\n",
            "0: ship                                          -- 15.2% -- ship\n",
            "1: plane                                         -- 13.1% -- ship\n",
            "2: car                                           -- 9.2% -- ship\n",
            "0: plane                                         -- 16.0% -- plane\n",
            "1: ship                                          -- 12.3% -- plane\n",
            "2: dog                                           -- 9.1% -- plane\n",
            "0: dog                                           -- 14.5% -- frog\n",
            "1: frog                                          -- 10.9% -- frog\n",
            "2: horse                                         -- 10.2% -- frog\n",
            "0: frog                                          -- 14.7% -- frog\n",
            "1: truck                                         -- 11.7% -- frog\n",
            "2: horse                                         -- 10.1% -- frog\n",
            "0: truck                                         -- 15.8% -- car\n",
            "1: car                                           -- 13.0% -- car\n",
            "2: horse                                         -- 9.0% -- car\n",
            "0: frog                                          -- 19.0% -- frog\n",
            "1: horse                                         -- 9.5% -- frog\n",
            "2: dog                                           -- 9.3% -- frog\n",
            "0: dog                                           -- 19.3% -- cat\n",
            "1: plane                                         -- 9.5% -- cat\n",
            "2: horse                                         -- 9.4% -- cat\n",
            "0: plane                                         -- 16.6% -- car\n",
            "1: ship                                          -- 12.6% -- car\n",
            "2: car                                           -- 8.9% -- car\n",
            "0: plane                                         -- 18.8% -- plane\n",
            "1: ship                                          -- 11.0% -- plane\n",
            "2: car                                           -- 8.8% -- plane\n",
            "0: dog                                           -- 15.2% -- truck\n",
            "1: horse                                         -- 10.8% -- truck\n",
            "2: cat                                           -- 10.1% -- truck\n",
            "0: frog                                          -- 12.7% -- dog\n",
            "1: dog                                           -- 12.3% -- dog\n",
            "2: horse                                         -- 11.1% -- dog\n",
            "0: truck                                         -- 15.3% -- horse\n",
            "1: car                                           -- 13.5% -- horse\n",
            "2: horse                                         -- 9.0% -- horse\n",
            "0: truck                                         -- 14.9% -- truck\n",
            "1: car                                           -- 11.7% -- truck\n",
            "2: ship                                          -- 10.2% -- truck\n",
            "0: dog                                           -- 19.5% -- ship\n",
            "1: horse                                         -- 9.6% -- ship\n",
            "2: bird                                          -- 9.1% -- ship\n",
            "0: dog                                           -- 15.8% -- dog\n",
            "1: horse                                         -- 11.8% -- dog\n",
            "2: cat                                           -- 9.5% -- dog\n",
            "0: dog                                           -- 14.5% -- horse\n",
            "1: plane                                         -- 11.5% -- horse\n",
            "2: horse                                         -- 10.0% -- horse\n",
            "0: ship                                          -- 13.4% -- ship\n",
            "1: truck                                         -- 12.1% -- ship\n",
            "2: plane                                         -- 10.2% -- ship\n",
            "0: dog                                           -- 13.1% -- frog\n",
            "1: frog                                          -- 12.6% -- frog\n",
            "2: horse                                         -- 10.5% -- frog\n",
            "0: dog                                           -- 17.3% -- horse\n",
            "1: horse                                         -- 11.1% -- horse\n",
            "2: frog                                          -- 9.2% -- horse\n",
            "0: plane                                         -- 16.1% -- plane\n",
            "1: dog                                           -- 11.9% -- plane\n",
            "2: horse                                         -- 9.3% -- plane\n",
            "0: car                                           -- 21.7% -- deer\n",
            "1: ship                                          -- 9.0% -- deer\n",
            "2: truck                                         -- 8.9% -- deer\n",
            "0: truck                                         -- 17.0% -- truck\n",
            "1: car                                           -- 10.4% -- truck\n",
            "2: horse                                         -- 9.8% -- truck\n",
            "0: dog                                           -- 19.0% -- dog\n",
            "1: horse                                         -- 10.0% -- dog\n",
            "2: bird                                          -- 9.2% -- dog\n",
            "0: dog                                           -- 17.4% -- bird\n",
            "1: horse                                         -- 10.4% -- bird\n",
            "2: bird                                          -- 9.5% -- bird\n",
            "0: frog                                          -- 15.9% -- deer\n",
            "1: dog                                           -- 10.9% -- deer\n",
            "2: horse                                         -- 10.2% -- deer\n",
            "0: dog                                           -- 20.4% -- plane\n",
            "1: horse                                         -- 9.6% -- plane\n",
            "2: bird                                          -- 8.8% -- plane\n",
            "0: dog                                           -- 15.5% -- truck\n",
            "1: horse                                         -- 10.9% -- truck\n",
            "2: truck                                         -- 9.6% -- truck\n",
            "0: frog                                          -- 20.6% -- frog\n",
            "1: deer                                          -- 9.1% -- frog\n",
            "2: horse                                         -- 9.0% -- frog\n",
            "0: frog                                          -- 20.3% -- frog\n",
            "1: deer                                          -- 9.1% -- frog\n",
            "2: horse                                         -- 9.1% -- frog\n",
            "0: dog                                           -- 19.0% -- dog\n",
            "1: horse                                         -- 9.8% -- dog\n",
            "2: frog                                          -- 9.2% -- dog\n",
            "0: dog                                           -- 20.8% -- deer\n",
            "1: horse                                         -- 9.3% -- deer\n",
            "2: bird                                          -- 8.9% -- deer\n",
            "0: dog                                           -- 17.8% -- dog\n",
            "1: horse                                         -- 10.8% -- dog\n",
            "2: cat                                           -- 9.1% -- dog\n",
            "0: car                                           -- 17.1% -- truck\n",
            "1: truck                                         -- 11.7% -- truck\n",
            "2: ship                                          -- 9.3% -- truck\n",
            "0: truck                                         -- 17.6% -- bird\n",
            "1: car                                           -- 11.3% -- bird\n",
            "2: horse                                         -- 9.1% -- bird\n",
            "0: dog                                           -- 17.6% -- deer\n",
            "1: horse                                         -- 10.5% -- deer\n",
            "2: frog                                          -- 9.2% -- deer\n",
            "0: plane                                         -- 18.0% -- car\n",
            "1: dog                                           -- 10.8% -- car\n",
            "2: ship                                          -- 9.1% -- car\n",
            "0: ship                                          -- 15.6% -- truck\n",
            "1: plane                                         -- 10.8% -- truck\n",
            "2: truck                                         -- 10.2% -- truck\n",
            "0: dog                                           -- 12.1% -- dog\n",
            "1: plane                                         -- 11.1% -- dog\n",
            "2: horse                                         -- 10.5% -- dog\n",
            "0: plane                                         -- 15.3% -- deer\n",
            "1: ship                                          -- 13.2% -- deer\n",
            "2: truck                                         -- 9.0% -- deer\n",
            "0: truck                                         -- 13.6% -- frog\n",
            "1: frog                                          -- 12.3% -- frog\n",
            "2: car                                           -- 9.9% -- frog\n",
            "0: truck                                         -- 16.3% -- dog\n",
            "1: car                                           -- 12.4% -- dog\n",
            "2: ship                                          -- 9.1% -- dog\n",
            "0: frog                                          -- 17.2% -- frog\n",
            "1: horse                                         -- 10.3% -- frog\n",
            "2: dog                                           -- 9.7% -- frog\n",
            "0: plane                                         -- 20.7% -- plane\n",
            "1: ship                                          -- 9.8% -- plane\n",
            "2: truck                                         -- 8.7% -- plane\n",
            "0: plane                                         -- 18.3% -- truck\n",
            "1: ship                                          -- 11.2% -- truck\n",
            "2: truck                                         -- 8.8% -- truck\n",
            "0: dog                                           -- 17.7% -- cat\n",
            "1: horse                                         -- 10.7% -- cat\n",
            "2: frog                                          -- 9.2% -- cat\n",
            "0: ship                                          -- 14.3% -- truck\n",
            "1: car                                           -- 13.2% -- truck\n",
            "2: truck                                         -- 9.5% -- truck\n",
            "0: frog                                          -- 18.1% -- horse\n",
            "1: bird                                          -- 10.0% -- horse\n",
            "2: deer                                          -- 9.8% -- horse\n",
            "0: frog                                          -- 19.9% -- frog\n",
            "1: deer                                          -- 9.7% -- frog\n",
            "2: bird                                          -- 9.0% -- frog\n",
            "0: ship                                          -- 13.6% -- truck\n",
            "1: car                                           -- 12.7% -- truck\n",
            "2: truck                                         -- 10.8% -- truck\n",
            "0: dog                                           -- 14.0% -- ship\n",
            "1: horse                                         -- 11.6% -- ship\n",
            "2: truck                                         -- 10.2% -- ship\n",
            "0: frog                                          -- 16.8% -- plane\n",
            "1: horse                                         -- 10.3% -- plane\n",
            "2: dog                                           -- 9.6% -- plane\n",
            "0: frog                                          -- 15.1% -- cat\n",
            "1: horse                                         -- 11.0% -- cat\n",
            "2: dog                                           -- 10.4% -- cat\n",
            "0: ship                                          -- 17.2% -- ship\n",
            "1: plane                                         -- 10.5% -- ship\n",
            "2: car                                           -- 9.8% -- ship\n",
            "0: plane                                         -- 15.8% -- ship\n",
            "1: ship                                          -- 11.6% -- ship\n",
            "2: dog                                           -- 9.5% -- ship\n",
            "0: dog                                           -- 18.2% -- horse\n",
            "1: horse                                         -- 10.5% -- horse\n",
            "2: cat                                           -- 9.3% -- horse\n",
            "0: frog                                          -- 15.2% -- horse\n",
            "1: truck                                         -- 10.8% -- horse\n",
            "2: horse                                         -- 10.1% -- horse\n",
            "0: dog                                           -- 16.6% -- deer\n",
            "1: plane                                         -- 11.4% -- deer\n",
            "2: horse                                         -- 9.6% -- deer\n",
            "0: dog                                           -- 18.2% -- frog\n",
            "1: horse                                         -- 10.2% -- frog\n",
            "2: plane                                         -- 9.5% -- frog\n",
            "0: dog                                           -- 18.4% -- horse\n",
            "1: horse                                         -- 9.9% -- horse\n",
            "2: bird                                          -- 9.3% -- horse\n",
            "0: frog                                          -- 13.1% -- cat\n",
            "1: dog                                           -- 11.4% -- cat\n",
            "2: horse                                         -- 11.0% -- cat\n",
            "0: truck                                         -- 15.6% -- frog\n",
            "1: frog                                          -- 10.6% -- frog\n",
            "2: car                                           -- 10.3% -- frog\n",
            "0: dog                                           -- 19.8% -- cat\n",
            "1: horse                                         -- 10.0% -- cat\n",
            "2: cat                                           -- 8.9% -- cat\n",
            "0: dog                                           -- 15.6% -- frog\n",
            "1: frog                                          -- 11.1% -- frog\n",
            "2: horse                                         -- 10.1% -- frog\n",
            "0: frog                                          -- 17.6% -- bird\n",
            "1: dog                                           -- 9.9% -- bird\n",
            "2: deer                                          -- 9.5% -- bird\n",
            "0: dog                                           -- 17.1% -- car\n",
            "1: horse                                         -- 11.2% -- car\n",
            "2: cat                                           -- 9.2% -- car\n",
            "0: plane                                         -- 20.8% -- bird\n",
            "1: ship                                          -- 9.8% -- bird\n",
            "2: dog                                           -- 8.7% -- bird\n",
            "0: truck                                         -- 14.6% -- cat\n",
            "1: horse                                         -- 10.7% -- cat\n",
            "2: frog                                          -- 10.1% -- cat\n",
            "0: dog                                           -- 13.4% -- horse\n",
            "1: horse                                         -- 12.1% -- horse\n",
            "2: truck                                         -- 10.8% -- horse\n",
            "0: dog                                           -- 17.6% -- bird\n",
            "1: plane                                         -- 10.1% -- bird\n",
            "2: horse                                         -- 9.8% -- bird\n",
            "0: frog                                          -- 19.4% -- frog\n",
            "1: truck                                         -- 9.3% -- frog\n",
            "2: horse                                         -- 9.2% -- frog\n",
            "0: plane                                         -- 15.4% -- ship\n",
            "1: dog                                           -- 12.2% -- ship\n",
            "2: horse                                         -- 9.4% -- ship\n",
            "0: ship                                          -- 17.0% -- ship\n",
            "1: plane                                         -- 11.8% -- ship\n",
            "2: car                                           -- 9.1% -- ship\n",
            "0: dog                                           -- 17.3% -- plane\n",
            "1: horse                                         -- 11.3% -- plane\n",
            "2: cat                                           -- 9.2% -- plane\n",
            "0: dog                                           -- 13.6% -- bird\n",
            "1: bird                                          -- 12.7% -- bird\n",
            "2: horse                                         -- 9.8% -- bird\n",
            "0: dog                                           -- 17.8% -- truck\n",
            "1: horse                                         -- 10.0% -- truck\n",
            "2: plane                                         -- 9.7% -- truck\n",
            "0: truck                                         -- 17.5% -- cat\n",
            "1: car                                           -- 10.6% -- cat\n",
            "2: horse                                         -- 9.3% -- cat\n",
            "0: frog                                          -- 18.2% -- cat\n",
            "1: horse                                         -- 10.2% -- cat\n",
            "2: dog                                           -- 9.3% -- cat\n",
            "0: plane                                         -- 20.2% -- ship\n",
            "1: dog                                           -- 9.5% -- ship\n",
            "2: ship                                          -- 9.0% -- ship\n",
            "0: plane                                         -- 18.3% -- ship\n",
            "1: ship                                          -- 9.9% -- ship\n",
            "2: dog                                           -- 9.8% -- ship\n",
            "0: truck                                         -- 17.2% -- car\n",
            "1: car                                           -- 10.9% -- car\n",
            "2: horse                                         -- 9.3% -- car\n",
            "0: dog                                           -- 18.2% -- car\n",
            "1: horse                                         -- 10.0% -- car\n",
            "2: bird                                          -- 9.4% -- car\n",
            "0: plane                                         -- 19.8% -- horse\n",
            "1: dog                                           -- 9.8% -- horse\n",
            "2: ship                                          -- 9.0% -- horse\n",
            "0: plane                                         -- 20.2% -- bird\n",
            "1: ship                                          -- 9.4% -- bird\n",
            "2: dog                                           -- 9.2% -- bird\n",
            "0: dog                                           -- 15.3% -- dog\n",
            "1: horse                                         -- 11.5% -- dog\n",
            "2: truck                                         -- 9.9% -- dog\n",
            "0: ship                                          -- 14.9% -- bird\n",
            "1: car                                           -- 11.8% -- bird\n",
            "2: truck                                         -- 10.4% -- bird\n",
            "0: plane                                         -- 16.3% -- horse\n",
            "1: dog                                           -- 11.0% -- horse\n",
            "2: ship                                          -- 9.4% -- horse\n",
            "0: dog                                           -- 17.6% -- ship\n",
            "1: plane                                         -- 10.0% -- ship\n",
            "2: horse                                         -- 10.0% -- ship\n",
            "0: plane                                         -- 14.8% -- truck\n",
            "1: ship                                          -- 13.3% -- truck\n",
            "2: truck                                         -- 9.2% -- truck\n",
            "0: plane                                         -- 15.7% -- plane\n",
            "1: ship                                          -- 13.1% -- plane\n",
            "2: car                                           -- 9.0% -- plane\n",
            "0: frog                                          -- 20.6% -- cat\n",
            "1: deer                                          -- 9.1% -- cat\n",
            "2: horse                                         -- 8.9% -- cat\n",
            "0: plane                                         -- 19.1% -- ship\n",
            "1: ship                                          -- 10.7% -- ship\n",
            "2: truck                                         -- 8.8% -- ship\n",
            "0: dog                                           -- 18.8% -- frog\n",
            "1: horse                                         -- 10.3% -- frog\n",
            "2: cat                                           -- 9.0% -- frog\n",
            "0: frog                                          -- 19.0% -- deer\n",
            "1: truck                                         -- 9.5% -- deer\n",
            "2: horse                                         -- 9.4% -- deer\n",
            "0: dog                                           -- 19.9% -- frog\n",
            "1: horse                                         -- 9.9% -- frog\n",
            "2: cat                                           -- 8.9% -- frog\n",
            "0: frog                                          -- 19.5% -- frog\n",
            "1: deer                                          -- 9.5% -- frog\n",
            "2: dog                                           -- 9.2% -- frog\n",
            "0: plane                                         -- 21.5% -- plane\n",
            "1: ship                                          -- 9.4% -- plane\n",
            "2: car                                           -- 8.6% -- plane\n",
            "0: dog                                           -- 14.7% -- plane\n",
            "1: plane                                         -- 13.1% -- plane\n",
            "2: horse                                         -- 9.5% -- plane\n",
            "0: dog                                           -- 19.4% -- horse\n",
            "1: horse                                         -- 10.1% -- horse\n",
            "2: cat                                           -- 9.0% -- horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Uc-2SSwiyum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}